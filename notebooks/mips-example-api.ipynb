{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "satisfactory-poetry",
   "metadata": {},
   "source": [
    "This notebook is to go through the MIP API for a classification project to determine how we might use it.\n",
    "\n",
    "We want to provide sensible defaults as well. We'll make some assumptions around cut points etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ahead-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "israeli-peninsula",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mip import Model, INTEGER, xsum, BINARY, minimize\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "military-authentication",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SLIMBinaryClassifier(ClassifierMixin):\n",
    "    def __init__(self, groups=None, Lambda=100, eps=0.1):\n",
    "        \"\"\"\n",
    "        SLIMClassifier assumes transformations are already\n",
    "        applied, and we're doing integer programming\n",
    "\n",
    "        Prior transformations are applied in the\n",
    "        SLIMTransformer.\n",
    "\n",
    "        TODO: Group sparsity constraints?\n",
    "        \"\"\"\n",
    "        self.m = Model()\n",
    "        self.Lambda = Lambda\n",
    "        self.eps = eps\n",
    "\n",
    "        self.groups = groups\n",
    "        self.lambda_ = None\n",
    "        self.M = None  # Lambda * max (X)\n",
    "\n",
    "    def _add_bias(self, X):\n",
    "        # adds bias to feature matrix\n",
    "        return np.hstack([np.ones(X.shape[0]).reshape(-1, 1), X])\n",
    "\n",
    "    def _update_label(self, y):\n",
    "        # makes it -1, 1 rather than 0, 1\n",
    "        return (y - 0.5) * 2\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = self._add_bias(X)\n",
    "        y = self._update_label(y)\n",
    "        n_instances = X.shape[0]\n",
    "        n_feats = X.shape[1]\n",
    "\n",
    "        # variables N + 3P\n",
    "        self.lambda_ = self.m.add_var_tensor(\n",
    "            shape=(n_feats,), name=\"lambda\", var_type=INTEGER\n",
    "        )\n",
    "        self.alpha_ = self.m.add_var_tensor(\n",
    "            shape=(n_instances,), name=\"alpha\", var_type=BINARY\n",
    "        )\n",
    "        self.beta_ = self.m.add_var_tensor(\n",
    "            shape=(n_feats,), name=\"beta\", var_type=BINARY\n",
    "        )\n",
    "        self.gamma_ = self.m.add_var_tensor(shape=(n_feats,), name=\"gammas\")\n",
    "\n",
    "        # constants\n",
    "        self.M = self.Lambda * np.max(X)\n",
    "        self.C_0 = 0.01\n",
    "        self.C_1 = 0.01\n",
    "\n",
    "        # add constraints.\n",
    "        self.m += self.lambda_ <= self.Lambda * self.beta_\n",
    "        self.m += self.lambda_ >= -self.Lambda * self.beta_\n",
    "        self.m += self.lambda_ <= self.gamma_\n",
    "        self.m += self.lambda_ >= -self.gamma_\n",
    "\n",
    "        #         for i in range(n_feats):\n",
    "        #             self.m += self.lambda_[i] <= self.Lambda * self.beta_[i]\n",
    "        #             self.m += self.lambda_[i] >= -self.Lambda * self.beta_[i]\n",
    "\n",
    "        #             self.m += self.lambda_[i] <= self.gamma_[i]\n",
    "        #             self.m += self.lambda_[i] >= -self.gamma_[i]\n",
    "\n",
    "        #         for i in range(n_instances):\n",
    "        #             self.m += (\n",
    "        #                 y[i] * (self.lambda_.dot(X[i, :]))\n",
    "        #                 <= self.M * (1 - self.alpha_[i]) + self.eps\n",
    "        #             )\n",
    "        #             self.m += (\n",
    "        #                 y[i] * (self.lambda_.dot(X[i, :]))\n",
    "        #                 >= -self.M * (self.alpha_[i]) + self.eps\n",
    "        #             )\n",
    "\n",
    "        self.m += (\n",
    "            y * X.dot(self.lambda_.reshape(-1, 1))\n",
    "            <= self.M * (1 - self.alpha_) + self.eps\n",
    "        )\n",
    "        self.m += (\n",
    "            y * X.dot(self.lambda_.reshape(-1, 1)) >= -self.M * (self.alpha_) + self.eps\n",
    "        )\n",
    "\n",
    "        # self.m.objective = (\n",
    "        #    self.alpha_.mean()\n",
    "        #    + self.C_0 * self.beta_.sum()\n",
    "        #    + self.C_1 * self.gamma_.sum()\n",
    "        # )\n",
    "        self.m.objective = self.alpha_.mean()\n",
    "        self.m.optimize()\n",
    "        return self\n",
    "\n",
    "    def raw_predict(self, X):\n",
    "        # X = self._add_bias(X)\n",
    "        n_instances = X.shape[0]\n",
    "        n_feats = X.shape[1]\n",
    "\n",
    "        return [\n",
    "            sum([X[i, ix] * self.lambda_[ix].x for ix in range(n_feats)])\n",
    "            for i in range(n_instances)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "physical-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_mod = SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "nutritional-popularity",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "deadly-nashville",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.929701230228471"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_mod.fit(data.data, data.target)\n",
    "svm_mod.score(data.data, data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "compatible-cartoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "southeast-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _, y, _ = train_test_split(\n",
    "    data.data, data.target, stratify=data.target, random_state=1, train_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "convenient-portfolio",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.SLIMBinaryClassifier at 0x7f19bfcbdcd0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = SLIMBinaryClassifier(eps=0.1)\n",
    "mod.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ready-aviation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinExprTensor([  0.,   0.,   0.,   0.,   0.,   0.,   0., 100.,   0.,   0.,\n",
       "                 0.,   0.,   0.,   0.,   0.,  14.,   0.,   0.,   0.,   0.,\n",
       "                 0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "                 0.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vectorize(lambda var: var.x)(mod.lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "respiratory-healing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6274165202108963\n",
      "1 0.5536028119507909\n",
      "2 0.4288224956063269\n",
      "3 0.2565905096660808\n",
      "4 0.14938488576449913\n",
      "5 0.0984182776801406\n",
      "6 0.09666080843585237\n",
      "7 0.12302284710017575\n",
      "8 0.14235500878734622\n",
      "9 0.18804920913884007\n",
      "10 0.2460456942003515\n",
      "11 0.27943760984182775\n",
      "12 0.30404217926186294\n",
      "13 0.31985940246045697\n",
      "14 0.3339191564147627\n",
      "15 0.3409490333919156\n",
      "16 0.3532513181019332\n",
      "17 0.36203866432337434\n",
      "18 0.36379613356766255\n",
      "19 0.36379613356766255\n",
      "20 0.37082601054481545\n",
      "21 0.37082601054481545\n"
     ]
    }
   ],
   "source": [
    "# get best cut point\n",
    "raw_score = np.array(mod.raw_predict(data.data))\n",
    "min_s, max_s = min(raw_score), max(raw_score)\n",
    "for cutpoint in range(int(min_s), int(max_s) + 1):\n",
    "    pred_target = raw_score > cutpoint\n",
    "    print(cutpoint, accuracy_score(data.target, pred_target * 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-healing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
